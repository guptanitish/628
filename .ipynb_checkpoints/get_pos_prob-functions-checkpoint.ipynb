{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import math\n",
      "import numpy as np\n",
      "from __future__ import division\n",
      "path = \"/home/stufs1/nitigupta/628/results/tagged_10000.txt\"\n",
      "df = pd.DataFrame.from_csv(path,header=None,index_col=None,sep='\\t')\n",
      "L = len(df)\n",
      "\n",
      "def make_index(l,d):\n",
      "    for i in range (0,len(l)):\n",
      "        d[l[i]]=i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos_tags_dict = dict()\n",
      "for i in range (0,L):\n",
      "    #print(df[][])\n",
      "    pos_tags_dict[df[1][i]]=1\n",
      "sorted(pos_tags_dict, key=pos_tags_dict.get)\n",
      "\n",
      "pos_tags_l = pos_tags_dict.keys()\n",
      "del pos_tags_dict\n",
      "pos_tags_l.sort()\n",
      "\n",
      "pos_tags_index_mapper = dict()\n",
      "make_index(pos_tags_l,pos_tags_index_mapper)\n",
      "del pos_tags_l\n",
      "\n",
      "pos_tags_count = len(pos_tags_index_mapper)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_dict = dict()\n",
      "for i in range (0,L):\n",
      "    #print(df[][])\n",
      "    word_dict[df[0][i]]=1\n",
      "sorted(word_dict, key=word_dict.get)\n",
      "\n",
      "word_l = word_dict.keys()\n",
      "del word_dict\n",
      "word_l.sort()\n",
      "\n",
      "word_index_mapper = dict()\n",
      "make_index(word_l,word_index_mapper)\n",
      "del word_l\n",
      "word_count = len(word_index_mapper)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def set_prob(arr,count1,count2):\n",
      "    \n",
      "    column_sum = np.zeros(count1)\n",
      "    for i in range(0,count1):\n",
      "        for j in range(0,count2):\n",
      "            column_sum[j]+=arr[i][j]\n",
      "    \n",
      "    for i in range(0,count1):\n",
      "        for j in range(0,count2):\n",
      "            arr[i][j] = arr[i][j]/column_sum[j]\n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#import seaborn as sns\n",
      "bi_word_arr = np.zeros( ( word_count,word_count) )\n",
      "\n",
      "for i in range(0,(L-1)):\n",
      "    #print(i)\n",
      "    bi_word_arr[word_index_mapper[df[0][i]]][word_index_mapper[df[0][i+1]]]+=1\n",
      "\n",
      "set_prob(bi_word_arr,len(bi_word_arr),len(bi_word_arr))\n",
      "total=0\n",
      "for i in range(0,len(bi_word_arr)):\n",
      "    total+=bi_word_arr[i][20]\n",
      "print(total)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "bi_arr = np.zeros( ( pos_tags_count,pos_tags_count) )\n",
      "\n",
      "for i in range(0,(L-1)):\n",
      "    #print(i)\n",
      "    bi_arr[pos_tags_index_mapper[df[1][i]]][pos_tags_index_mapper[df[1][i+1]]]+=1\n",
      "\n",
      "set_prob(bi_arr,len(bi_arr),len(bi_arr))\n",
      "total=0\n",
      "for i in range(0,len(bi_arr)):\n",
      "    total+=bi_arr[i][20]\n",
      "print(total)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#in progress\n",
      "pos_to_word_dict= dict()\n",
      "for i in range(0,L):\n",
      "    #print(i)\n",
      "    w1=df[0][i]\n",
      "    w2=df[0][i]\n",
      "    bi_word_arr[word_index_mapper[df[0][i]]][word_index_mapper[df[0][i+1]]]+=1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#import seaborn as sns\n",
      "bi_word_dict = dict()\n",
      "\n",
      "def update_dict(d):\n",
      "    \n",
      "    if w1 not in d:\n",
      "        d[w1]= {}\n",
      "        d[w1][w2]=1\n",
      "    else:\n",
      "        if w2 not in d[w1]:\n",
      "            d[w1][w2]=1\n",
      "        else:\n",
      "            d[w1][w2]+=1\n",
      "def convert_to_prob(d):\n",
      "    for outer_key in d:\n",
      "        count = 0\n",
      "        for inner_key in d[outer_key]:\n",
      "            count+=d[outer_key][inner_key]\n",
      "        for inner_key in d[outer_key]:\n",
      "            d[outer_key][inner_key] = d[outer_key][inner_key]/count\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "   \n",
      "\n",
      "for i in range(0,(L-1)):\n",
      "    #print(i)=\n",
      "    '''\n",
      "    w1=word_index_mapper[df[0][i]]\n",
      "    w2=word_index_mapper[df[0][i+1]]\n",
      "    '''\n",
      "    \n",
      "    w1=df[0][i]\n",
      "    w2=df[0][i+1]\n",
      "    if type(w1)==str:\n",
      "        w1=w1.lower()\n",
      "    if type(w2)==str:\n",
      "        w2=w2.lower()\n",
      "    update_dict(bi_word_dict)\n",
      "\n",
      "\n",
      "#if probabilities are required, execute this also:\n",
      "convert_to_prob(bi_word_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "def set_prob_word(arr,count1,count2):\n",
      "    \n",
      "    column_sum = np.zeros(count1)\n",
      "    for i in range(0,count1):\n",
      "        for j in range(0,count2):\n",
      "            column_sum[j]+=arr[i][j]\n",
      "    \n",
      "    for i in range(0,count1):\n",
      "        for j in range(0,count2):\n",
      "            arr[i][j] = arr[i][j]/column_sum[j]\n",
      "'''            \n",
      "            \n",
      "word_arr = np.zeros( (word_count,pos_tags_count) )\n",
      "\n",
      "for i in range(0,(L-1)):\n",
      "    #print(i)\n",
      "    word_arr[word_index_mapper[df[0][i]]][pos_tags_index_mapper[df[1][i+1]]]+=1 \n",
      "    \n",
      "set_prob(word_arr,word_count,pos_tags_count)\n",
      "\n",
      "total=0\n",
      "for i in range(0,pos_tags_count):\n",
      "    total+=word_arr[20][i]\n",
      "print(total)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.77955360369e-05\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tri_arr = np.zeros( (pos_tags_count,pos_tags_count,pos_tags_count) )\n",
      "\n",
      "for i in range(0,(L-2)):\n",
      "    #print(i)\n",
      "    tri_arr[pos_tags_index_mapper[df[1][i]]][pos_tags_index_mapper[df[1][i+1]]][pos_tags_index_mapper[df[1][i+2]]]+=1\n",
      "\n",
      "tri_column_sum=np.zeros( (pos_tags_count,pos_tags_count) )\n",
      "\n",
      "#column_sum = np.zeros(len(tri_arr))\n",
      "\n",
      "for i in range(0,len(tri_arr)):\n",
      "    for j in range(0,len(tri_arr)):\n",
      "        for k in range(0,len(tri_arr)):\n",
      "            tri_column_sum[i][j]+=tri_arr[i][j][k]\n",
      "\n",
      "for i in range(0,len(tri_arr)):\n",
      "    for j in range(0,len(tri_arr)):\n",
      "        for k in range(0,len(tri_arr)):\n",
      "            tri_arr[i][j][k] = tri_arr[i][j][k]/(tri_column_sum[i][j]+1)\n",
      "\n",
      "total=0.0\n",
      "for i in range(0,len(tri_arr)):\n",
      "    for j in range(0,len(tri_arr)):\n",
      "        total+=tri_arr[i][j][20]\n",
      "    \n",
      "print(total)\n",
      "print(tri_arr[20][20][20])\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "123.567811968\n",
        "0.0868395303327\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(bi_arr[pos_tags_index_mapper['VB'],pos_tags_index_mapper['MD']]*1000)\n",
      "print(bi_arr[pos_tags_index_mapper['MD'],pos_tags_index_mapper['VB']]*1000)\n",
      "print(tri_arr[pos_tags_index_mapper['NN'],pos_tags_index_mapper['MD'],pos_tags_index_mapper['VB']]*1000)\n",
      "print(word_arr[word_index_mapper['may'],pos_tags_index_mapper['VB']]*1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.24223602484\n",
        "269.603029878\n",
        "64.9368863955\n",
        "15.710478328\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "bi_word_path = \"/home/stufs1/nitigupta/628/pickled_ds/bi_word.txt\"\n",
      "\n",
      "def save_to_disk(ds,path):\n",
      "    print(\"Pickling to... \",path)\n",
      "    dumpfile=open(path,'wb')\n",
      "    pickle.dump(ds,dumpfile)\n",
      "    dumpfile.close()\n",
      "    print(\"Done Pickling...\")\n",
      "    \n",
      "def load_from_disk(path):\n",
      "    print(\"Unpickling...\")\n",
      "    unpickled_file=open(path,'rb')\n",
      "    ds=pickle.load(unpickled_file)\n",
      "    print(\"Done Pickling...\")\n",
      "    return ds\n",
      "\n",
      "save_to_disk(bi_word_dict,bi_word_path)\n",
      "d = load_from_disk(bi_word_path)\n",
      "len(d)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('Pickling to... ', '/home/stufs1/nitigupta/628/pickled_ds/bi_word.txt')\n",
        "Done Pickling..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Unpickling...\n",
        "Done Pickling..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "26095"
       ]
      }
     ],
     "prompt_number": 45
    }
   ],
   "metadata": {}
  }
 ]
}